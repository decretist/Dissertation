{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burrows's Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './corpus/a/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_tokens(filename):\n",
    "    '''open text file and return list of tokens'''\n",
    "    # text = open(filename, 'r').read().lower()\n",
    "    f = open(filename, 'r') # open file\n",
    "    text = f.read() # read file\n",
    "    text = text.lower() # lower-case text\n",
    "    tokens = [word for word in re.split('\\W', text) if word != ''] # remove punctuation\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(samples):\n",
    "    tokens = []\n",
    "    for sample in samples:\n",
    "        tokens += get_tokens(path + sample + '.txt')\n",
    "    types = list(set(tokens)) # create unordered list of unique words\n",
    "    tmp = dict.fromkeys(types, 0) # create temporary dictionary, initialize counts to 0\n",
    "    for token in tokens: tmp[token] += 1 # count words\n",
    "    # re-order words in temporary dictionary numerically by descending frequency\n",
    "    # re-order words with same frequency alphabetically\n",
    "    features = { \n",
    "        key: value for key, value in sorted(tmp.items(),\n",
    "        key = lambda item: (-item[1], item[0]))\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_counts(features, samples):\n",
    "    columns = {}\n",
    "    for sample in samples:\n",
    "        columns[sample] = []\n",
    "        tmp = get_features([sample])\n",
    "        for feature in features:\n",
    "            columns[sample].append(tmp.get(feature, 0))\n",
    "    return pd.DataFrame(columns, index = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths(samples):\n",
    "    filenames = [path + sample + '.txt' for sample in samples]\n",
    "    lengths = {}\n",
    "    for i in range(len(samples)):\n",
    "       lengths[samples[i]] = len(get_tokens(filenames[i]))\n",
    "    return pd.DataFrame(lengths, index = ['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian0</th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-2.8702</td>\n",
       "      <td>-0.4342</td>\n",
       "      <td>-0.7095</td>\n",
       "      <td>1.1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>-6.5491</td>\n",
       "      <td>-0.0361</td>\n",
       "      <td>1.0176</td>\n",
       "      <td>-0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>-3.2375</td>\n",
       "      <td>-0.9786</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>-0.0414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>-3.5264</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>-1.1412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gratian0  Gratian1   dePen  Gratian2\n",
       "in    -2.8702   -0.4342 -0.7095    1.1437\n",
       "non   -6.5491   -0.0361  1.0176   -0.9814\n",
       "et    -3.2375   -0.9786  1.0201   -0.0414\n",
       "est   -3.5264    0.4179  0.7233   -1.1412"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = 4 # 4 most frequent words (MFWs)\n",
    "samples = ['Gratian1', 'dePen', 'Gratian2']\n",
    "unknown = 'Gratian0'\n",
    "features = get_features(samples)\n",
    "mfws = list(features.keys())[:limit]\n",
    "counts = get_counts(mfws, [unknown] + samples)\n",
    "lengths = get_lengths([unknown] + samples)\n",
    "frequencies = (counts / lengths.values) * 1000\n",
    "means = frequencies[samples].mean(axis = 1).to_frame('mean')\n",
    "standard_deviations = frequencies[samples].std(axis = 1).to_frame('std')\n",
    "z_scores = (frequencies - means.values) / standard_deviations.values\n",
    "# pd.options.display.float_format = '{:,.4f}'.format\n",
    "f = open('./burrows.md', 'w')\n",
    "f.write(\"---\\nauthor: Paul Evans\\ntitle: Chapter 4\\nsubtitle: Burrows's Delta Tables\\n---\\n\\n\") # YAML header\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "f.write(z_scores.round(4).to_markdown() + '\\n\\n')\n",
    "z_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     |   Gratian0 |   Gratian1 |   dePen |   Gratian2 |\n",
    "|:----|-----------:|-----------:|--------:|-----------:|\n",
    "| in  |    -2.8702 |    -0.4342 | -0.7095 |     1.1437 |\n",
    "| non |    -6.5491 |    -0.0361 |  1.0176 |    -0.9814 |\n",
    "| et  |    -3.2375 |    -0.9786 |  1.0201 |    -0.0414 |\n",
    "| est |    -3.5264 |     0.4179 |  0.7233 |    -1.1412 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples presented in the previous section are suggestive of ways in which differences between the frequencies of occurrence of common words in samples from a corpus of texts can be quantified in statistically meaningful units (standard deviations or values of z) and combined to represent the distance between those samples.  This technique is, however, of limited value so long as we are restricted to the two, or at most three, dimensions the human mind is capable of visualizing. In 2001, John F. Burrows (d.2019) of the University of Newcastle, Australia, proposed a generalization that gets around the limitation on the number of features to two or three by averaging z-score distance measurements of word frequency data for any number of features. This has the effect of collapsing distance measurements in an arbitrary number of dimensions into a single metric. Burrows called this metric the Delta, and it is now generally referred to as Burrows's Delta ($\\Delta_B$). Expositions of Burrows's Delta sometime fail to make a clear enough distinction between the metric $\\Delta_B$ and the authorship attribution methodology in which Burrows applied it. The metric is not the methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempts to attribute authorship are typically undertaken in scenarios where there is a large (enough) number of texts securely attributable to a known author, and a text, or at most a small number of texts, of unknown authorship. The attempt is then made to attribute the unknown text to one of the known authors, or to rule out such an attribution. Take the *Federalist* as an example. There are numbers of the *Federalist* of disputed or unknown attribution, a small and well-defined number of candidates for authorship---Hamilton, Jay, Madison---to whom those numbers might be attributed, and securely attributed samples from each of the candidates, conveniently enough from the same work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burrows's methodology assumes just such a scenario. He began by identifying the most frequent words (MFWs) in the corpus of comparison texts securely attributed to known authors. In Burrows's published descriptions of his methodology, he typically used all of the 30 most frequent words in the corpus of attributed comparison texts without distinguishing between function and content words. He then tabulated the number of occurrences of the most frequent words in each of the sample texts in the comparison corpus and normalized their frequency of occurrence as a percentage. Burrows then used the frequency data collected from the comparison texts to calculate a mean frequency of occurrence and sample standard deviation for each of the MFWs or features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to emphasize that the mean frequency of feature occurrence calculated at this stage of Burrows's algorithm and subsequently used to calculate the sample standard deviation for each feature is **not** the overall mean frequency across the corpus of attributed comparison text samples. Instead, the comparison corpus feature mean is calculated by averaging the normalized (percentage) frequency for each feature across all of the text samples in the attributed comparison corpus, without concern for differences in size (word count) between the samples. To refer back to the example presented in the previous section as part of the two-dimensional visualization demonstration, we did **not** use the **overall** mean frequency of *in* across the three samples Gratian1, dePen, and Gratian2, (2,113 occurrences out of 81,049 words or 26.0706 per 1,000), but rather the mean of the normalized frequencies of *in* for each of the samples (the mean of 25.5673, 24.9975, and 28.8320, or 26.4656 occurrences per 1,000). **(mean of means)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the mean of means and sample standard deviation for each of the features (MFWs), Burrows then converted the normalized (percentage) frequencies of occurrence for each feature in each sample in the comparison corpus to z-scores by subtracting the mean of means from the frequency and dividing the positive or negative difference by the standard deviation for the feature. At this point, Burrows turned his attention to the unattributed text, tabulating all occurrences of the 30 MFWs for which data had been collected from the comparison texts, then normalizing the word counts by converting them to percentage frequencies of occurrence. Burrows then converted the normalized frequencies for each feature in the unattributed test sample to z-scores based on the values for the mean of means and sample standard deviation derived from the feature frequencies in the attributed comparison corpus samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these preliminaries out of the way, Burrows then calculated the value of the Delta by taking the average (arithmetic mean) of the absolute value of the differences between the z-score for a given feature (MFW) for the unattributed test sample and each of the comparison samples in the corpus of attributed texts. In Burrows's interpretation, the comparison test sample from the attributed corpus with the lowest Delta with respect to the unattributed test sample was most likely to share a common author with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to apply Burrow's methodology in the case of the *dicta* from Gratian's *Decretum* without modification. As the survey in Chapter 3 above indicated, near-contemporaries knew next to nothing about Gratian. Perhaps most notably, although Gratian was thought to have been a teacher, no one in the generation following made an unambiguous claim to have been his student. There are no other writings securely, or even insecurely, attributed to him. Fortunately, Burrows's Delta can be readily adapted to the particular situation in which we find ourselves, where there are no other texts attributed to Gratian with which we can compare, for example, the hypothetical case statements (*themata*) or second-recension *dicta*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although other distance methods of authorship attribution have been proposed since,[@evert_understanding_2017] Burrows's Delta is widely accepted in the scholarly literature of the field of computational linguistics, and it will therefore be used as the basis for the demonstrations in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first experiment will be a comparison of four subcorpora, Gratian0 (the hypothetical case statements or *themata*), Gratian1 (the first-recension *dicta* excluding the *dicta* from *de Penitentia*), dePen (first- and second-recension *dicta* from *de Penitentia*), and Gratian2 (the second-recension *dicta* excluding the *dicta* from *de Penitentia*), using the frequencies of occurrence of the four most frequent words (MFWs) in Gratian's *dicta* as the basis for comparison. We will hypothesize that the subcorpus containing the hypothetical case statements (*themata*) is the work of an unknown author, and will treat the other three subcorpora as making up a corpus of works by a known author. Using four subcorpora and four features, where every feature analyzed is represented in a different dimension, demonstrates that z-score distance methods can be extended to cases in which the number of dimensions is greater than three. It also has the advantage of making the solution compact enough to allow readers to follow along and reassure themselves of the mathematical validity of all of the intermediate steps leading to the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first experiment resumes directly where the two-dimensional visualization demonstration left off, so all of the function definitions and variable values in force at the conclusion of that demonstration are still valid. In particular, this experiment inherits the z-scores for all of the four most frequent words (MFWs). While we disregarded the data for the third and fourth most frequent words (*et* and *est*) for the purpose of the visualization demonstration, they will be fully taken into account here. (Remember that the values for mean and standard deviations used to derive the z-scores were calculated without reference to the Gratian0 sample here being treated as the unknown)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, split the z-scores into two new dataframes, one for the test sample Gratian0, assumed for the purpose of this experiment to be the work of an unknown author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-2.8702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>-6.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>-3.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>-3.5264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gratian0\n",
       "in    -2.8702\n",
       "non   -6.5491\n",
       "et    -3.2375\n",
       "est   -3.5264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = z_scores[[unknown]]\n",
    "f.write(test.round(4).to_markdown() + '\\n\\n')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     |   Gratian0 |\n",
    "|:----|-----------:|\n",
    "| in  |    -2.8702 |\n",
    "| non |    -6.5491 |\n",
    "| et  |    -3.2375 |\n",
    "| est |    -3.5264 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the other for the comparison samples Gratian1, dePen, and Gratian2, assumed for the purpose of this experiment to represent the work of known authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-0.4342</td>\n",
       "      <td>-0.7095</td>\n",
       "      <td>1.1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>-0.0361</td>\n",
       "      <td>1.0176</td>\n",
       "      <td>-0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>-0.9786</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>-0.0414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>-1.1412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gratian1   dePen  Gratian2\n",
       "in    -0.4342 -0.7095    1.1437\n",
       "non   -0.0361  1.0176   -0.9814\n",
       "et    -0.9786  1.0201   -0.0414\n",
       "est    0.4179  0.7233   -1.1412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = z_scores[samples]\n",
    "f.write(corpus.round(4).to_markdown() + '\\n\\n')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     |   Gratian1 |   dePen |   Gratian2 |\n",
    "|:----|-----------:|--------:|-----------:|\n",
    "| in  |    -0.4342 | -0.7095 |     1.1437 |\n",
    "| non |    -0.0361 |  1.0176 |    -0.9814 |\n",
    "| et  |    -0.9786 |  1.0201 |    -0.0414 |\n",
    "| est |     0.4179 |  0.7233 |    -1.1412 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula used to calculate Burrows's Delta is:\n",
    "\n",
    "$\\Delta_B = \\frac{1}{N}\\sum_{i = 1}^N|z_i(t) - z_i(c)|$\n",
    "\n",
    "![Burrows's Delta](JPGs/Burrows.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easiest to deal with the formula in two steps, first evaluating the expression $|z_i(t) - z_i(c)|$. Note that because we take the absolute value of the result, the order of operands on either side of the subtraction operator '-' does not matter. For each of the three columns (Gratian1, dePen, and Gratian2) in the *corpus* dataframe, subtract the z-score in each row from the z-score in the same row of the *test* (Gratian0) dataframe, take the absolute value, and record the result in the corresponding column and row of the *differences* dataframe. For example, the z-score for *non* in *test* (Gratian0) is -6.5491, the z-score for *non* in the Gratian1 column of *corpus* is -0.0361, so the absolute value of the difference recorded in the *non* row of the Gratian1 column of *differences* would be 6.5130."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>2.4360</td>\n",
       "      <td>2.1606</td>\n",
       "      <td>4.0139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>6.5130</td>\n",
       "      <td>7.5667</td>\n",
       "      <td>5.5677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>2.2589</td>\n",
       "      <td>4.2576</td>\n",
       "      <td>3.1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>3.9443</td>\n",
       "      <td>4.2497</td>\n",
       "      <td>2.3852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gratian1  dePen  Gratian2\n",
       "in     2.4360 2.1606    4.0139\n",
       "non    6.5130 7.5667    5.5677\n",
       "et     2.2589 4.2576    3.1961\n",
       "est    3.9443 4.2497    2.3852"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences = (test.values - corpus).abs()\n",
    "f.write(differences.round(4).to_markdown() + '\\n\\n')\n",
    "differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     |   Gratian1 |   dePen |   Gratian2 |\n",
    "|:----|-----------:|--------:|-----------:|\n",
    "| in  |     2.436  |  2.1606 |     4.0139 |\n",
    "| non |     6.513  |  7.5667 |     5.5677 |\n",
    "| et  |     2.2589 |  4.2576 |     3.1961 |\n",
    "| est |     3.9443 |  4.2497 |     2.3852 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the layout of the *differences* dataframe in which we have stored the intermediate results, the part of the formula we deferred dealing with ($\\frac{1}{N}\\sum_{i = 1}^N$) is simply a notationally exact way of indicating that we are to take the average (arithmetic mean) of the values in each of the columns, and record the resulting value of $\\Delta_B$ in the corresponding column of the *deltas* dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Burrows's Delta measures Manhattan Distance.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seemingly simple act of taking the arithmetic mean (average) of the z-score distances between the samples for each feature has an interesting and non-intuitive implication. It was mentioned in passing in the previous section on visualization that plotting the z-score coordinates of word frequencies invokes the tacit assumption that the axes are in fact perpendicular to one another, an assumption that is at least potentially open to challenge. Burrows's Delta generalizes this assumption into an arbitrary number of dimension. The scholarly literature on authorship attribution methods describes distance metrics such as Burrows's Delta as measuring 'Manhattan Distance'. The analogy is to walking or driving from a starting to an ending point through a space in which the street have been laid out at right angles to one another, like Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gratian0</th>\n",
       "      <td>3.7880</td>\n",
       "      <td>4.5586</td>\n",
       "      <td>3.7907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gratian1  dePen  Gratian2\n",
       "Gratian0    3.7880 4.5586    3.7907"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = (differences.mean(axis = 0)).to_frame(unknown).transpose()\n",
    "f.write(row.round(4).to_markdown() + '\\n\\n')\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          |   Gratian1 |   dePen |   Gratian2 |\n",
    "|:---------|-----------:|--------:|-----------:|\n",
    "| Gratian0 |      3.788 |  4.5586 |     3.7907 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gratian1 subcorpus is just slightly closer than the Gratian2 subcorpus to the unknown Gratian0 test case, with values of Delta for both rounding to 3.79. A candidate is defined as being *closest* to the unknown when it has the lowest mean of the absolute values of the differences between the z-scores for the unknown and the candidate.But as Burrows pointed out, one candidate will always have the lowest $\\Delta_B$, so that in itself is not enough to make or to rule out an attribution of authorship. We will need further information before we can provide any kind of interpretation for the result. The most we can say based on this result is that the hypothetical case statements are less likely to have been written by the author of the *dicta* in *de Penitentia* than by the authors of either the first- or second-recension *dicta*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second experiment is a variation on the first, in which a 3881-word sample made up of seven extended passages from the pseudo-Augustinian *De vera et falsa penitentia* quoted by Gratian in *de Penitentia* are substituted for the 3605-word sample containing the hypothetical case statements.[^b3] As noted in Chapter 0 above, Gratian can be said with a high degree of confidence **not** to be the author of *De vera et falsa penitentia*. The authors are strongly distinguished by their choice of post-positive conjunctions: Gratian has a preference for *autem*, while pseudo-Augustine has an even stronger preference for *enim*. Substituting the pseudo-Augustinian sample in place of the case statements demonstrates the kinds of results to be expected from Burrows's Delta in a situation in which an attribution of authorship can reasonably be ruled out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>psAug</th>\n",
       "      <td>2.6456</td>\n",
       "      <td>1.7373</td>\n",
       "      <td>3.4318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gratian1  dePen  Gratian2\n",
       "psAug    2.6456 1.7373    3.4318"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = 4 # 4 most frequent words (MFWs)\n",
    "samples = ['Gratian1', 'dePen', 'Gratian2']\n",
    "unknown = 'psAug'\n",
    "features = get_features(samples)\n",
    "mfws = list(features.keys())[:limit]\n",
    "counts = get_counts(mfws, [unknown] + samples)\n",
    "lengths = get_lengths([unknown] + samples)\n",
    "frequencies = (counts / lengths.values) * 1000\n",
    "means = frequencies[samples].mean(axis = 1).to_frame('mean')\n",
    "standard_deviations = frequencies[samples].std(axis = 1).to_frame('std')\n",
    "z_scores = (frequencies - means.values) / standard_deviations.values\n",
    "test = z_scores[[unknown]]\n",
    "corpus = z_scores[samples]\n",
    "differences = (test.values - corpus).abs()\n",
    "row = (differences.mean(axis = 0)).to_frame(unknown).transpose()\n",
    "f.write(row.round(4).to_markdown() + '\\n\\n')\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |   Gratian1 |   dePen |   Gratian2 |\n",
    "|:------|-----------:|--------:|-----------:|\n",
    "| psAug |     2.6456 |  1.7373 |     3.4318 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third experiment extends the first by treating each of the subcorpora, Gratian0, Gratian1, dePen, and Gratian2 sequentially as the work of an unknown author, and the other three subcorpora as constituting a corpus of works by a known author. This is an attempt to demonstrate the adaptation of Burrows's technique in a circumstance in which there are no securely attributed comparison texts outside of the corpus, and in which there is some reason to suspect that there are multiple authors at work within the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gratian0</th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gratian0</th>\n",
       "      <td>nan</td>\n",
       "      <td>3.7880</td>\n",
       "      <td>4.5586</td>\n",
       "      <td>3.7907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gratian1</th>\n",
       "      <td>1.4361</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3628</td>\n",
       "      <td>0.5453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dePen</th>\n",
       "      <td>1.9873</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gratian2</th>\n",
       "      <td>1.7185</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gratian0  Gratian1  dePen  Gratian2\n",
       "Gratian0       nan    3.7880 4.5586    3.7907\n",
       "Gratian1    1.4361       nan 0.3628    0.5453\n",
       "dePen       1.9873    0.4515    nan    0.7673\n",
       "Gratian2    1.7185    0.6278 0.7905       nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './corpus/a/'\n",
    "\n",
    "# author candidates, e.g. Gratian 1, the Master of Penance, Gratian 2, etc.\n",
    "candidates = ['Gratian0', 'Gratian1', 'dePen', 'Gratian2']\n",
    "deltas = pd.DataFrame(columns = candidates)\n",
    "limit = 4 # 4 most frequent words (MFWs)\n",
    "for candidate in candidates:\n",
    "    unknown = candidate\n",
    "    samples = candidates[:]\n",
    "    samples.remove(unknown)\n",
    "    features = get_features(samples)\n",
    "    mfws = list(features.keys())[:limit]\n",
    "    counts = get_counts(mfws, [unknown] + samples)\n",
    "    lengths = get_lengths([unknown] + samples)\n",
    "    frequencies = (counts / lengths.values) * 1000\n",
    "    means = frequencies[samples].mean(axis = 1).to_frame('mean')\n",
    "    standard_deviations = frequencies[samples].std(axis = 1).to_frame('std')\n",
    "    z_scores = (frequencies - means.values) / standard_deviations.values\n",
    "    test = z_scores[[unknown]]\n",
    "    corpus = z_scores[samples]\n",
    "    differences = (test.values - corpus).abs()\n",
    "    row = (differences.mean(axis = 0)).to_frame(unknown).transpose()\n",
    "    deltas = deltas.append(row)\n",
    "# csv = open('./CSVs/deltas.csv', 'w')\n",
    "# csv.write(deltas.to_csv())\n",
    "# csv.close()\n",
    "f.write(deltas.round(4).to_markdown() + '\\n\\n')\n",
    "deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          |   Gratian0 |   Gratian1 |    dePen |   Gratian2 |\n",
    "|:---------|-----------:|-----------:|---------:|-----------:|\n",
    "| Gratian0 |   nan      |     3.788  |   4.5586 |     3.7907 |\n",
    "| Gratian1 |     1.4361 |   nan      |   0.3628 |     0.5453 |\n",
    "| dePen    |     1.9873 |     0.4515 | nan      |     0.7673 |\n",
    "| Gratian2 |     1.7185 |     0.6278 |   0.7905 |   nan      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the results of the first three experiments together, we can start to form some very preliminary conclusions. Based on the values for $\\Delta_B$ in the table above, the most likely attribution is that the first-recension *dicta* (Gratian1) and the *dicta* from *de Penitentia* (dePen) have the same author. It is less likely that the first-recension *dicta* (Gratian1) and the second-recension *dicta* (Gratian2) have the same author. It is less likely still that the *dicta* from *de Penitentia* and the second-recension *dicta* have the same author. It is much less likely that the case statements (Gratian0) have the same author as either the first- (Gratian1) or second-recension (Gratian2) *dicta*. Finally, the least likely attribution is that the case statements (Gratian0) have the same author as the *dicta* from *de Penitentia*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psAug</th>\n",
       "      <th>Gratian1</th>\n",
       "      <th>dePen</th>\n",
       "      <th>Gratian2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>psAug</th>\n",
       "      <td>nan</td>\n",
       "      <td>2.6456</td>\n",
       "      <td>1.7373</td>\n",
       "      <td>3.4318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gratian1</th>\n",
       "      <td>1.0228</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>0.9325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dePen</th>\n",
       "      <td>0.5178</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gratian2</th>\n",
       "      <td>5.2005</td>\n",
       "      <td>3.3574</td>\n",
       "      <td>4.2857</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          psAug  Gratian1  dePen  Gratian2\n",
       "psAug       nan    2.6456 1.7373    3.4318\n",
       "Gratian1 1.0228       nan 0.4653    0.9325\n",
       "dePen    0.5178    0.4733    nan    1.3453\n",
       "Gratian2 5.2005    3.3574 4.2857       nan"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './corpus/a/'\n",
    "\n",
    "# author candidates, e.g. pseudo-Augustine, Gratian 1, the Master of Penance, Gratian 2, etc.\n",
    "candidates = ['psAug', 'Gratian1', 'dePen', 'Gratian2']\n",
    "deltas = pd.DataFrame(columns = candidates)\n",
    "limit = 4 # 4 most frequent words (MFWs)\n",
    "for candidate in candidates:\n",
    "    unknown = candidate\n",
    "    samples = candidates[:]\n",
    "    samples.remove(unknown)\n",
    "    features = get_features(samples)\n",
    "    mfws = list(features.keys())[:limit]\n",
    "    counts = get_counts(mfws, [unknown] + samples)\n",
    "    lengths = get_lengths([unknown] + samples)\n",
    "    frequencies = (counts / lengths.values) * 1000\n",
    "    means = frequencies[samples].mean(axis = 1).to_frame('mean')\n",
    "    standard_deviations = frequencies[samples].std(axis = 1).to_frame('std')\n",
    "    z_scores = (frequencies - means.values) / standard_deviations.values\n",
    "    test = z_scores[[unknown]]\n",
    "    corpus = z_scores[samples]\n",
    "    differences = (test.values - corpus).abs()\n",
    "    row = (differences.mean(axis = 0)).to_frame(unknown).transpose()\n",
    "    deltas = deltas.append(row)\n",
    "deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth and final experiment will compare the thirty most frequent words (MFWs) across fourteen subcorpora: cases (C.1-36 d.init.), laws (D.1-20 R1 *dicta*), orders1 (D.21-80 R1 *dicta*), orders2 (D.81-101 R1 *dicta*), simony (C.1 R1 *dicta*), procedure (C.2-6 R1 *dicta*), other1 (C.7-10 R1 *dicta*), other2 (C.11-15 R1 *dicta*), monastic (C.16-20 R1 *dicta*), other3 (C.21-22 R1 *dicta*), heresy (C.23-26 R1 *dicta*), marriage (C.27-36 R1 *dicta*), penance (R1 and R2 *dicta* from *de Penitentia*), and second (all R2 *dicta*, excluding those from *de Penitentia*).[<sup>4</sup>](#fn4) For each of the fourteen subcorpora, we will hypothesize each subcorpus in turn to be the work of an unknown author, and will treat the other thirteen subcorpora as composing a corpus of works by a known author. The scale of the fourth experiment is similar to that of the experiments carried out by John Burrows and David Hoover, the pioneers of the technique, but makes it impractical to show intermediate results at every step in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"fn4\">The division of the first-recension (R1) dicta into twelve sections follows the division of Gratian’s Decretum proposed by Alfred Beyer in *Lokale Abbreviationen Des Decretum Gratiani: Analyse Und Vergleich Der Dekretabbreviationen \"Omnes Leges Aut Divine\" (Bamberg), \"Humanum Genus Duobus Regitur\" (Pommersfelden) Und \"de His Qui Intra Claustra Monasterii Consistunt\" (Lichtenthal, Baden-Baden)*, Bamberger Theologische Studien ; Bd. 6 (Frankfurt am Main ; PLang, 1998), 17-18.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>laws</th>\n",
       "      <th>orders1</th>\n",
       "      <th>orders2</th>\n",
       "      <th>simony</th>\n",
       "      <th>procedure</th>\n",
       "      <th>other1</th>\n",
       "      <th>other2</th>\n",
       "      <th>monastic</th>\n",
       "      <th>other3</th>\n",
       "      <th>heresy</th>\n",
       "      <th>marriage</th>\n",
       "      <th>penance</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cases</th>\n",
       "      <td>nan</td>\n",
       "      <td>2.2765</td>\n",
       "      <td>1.9247</td>\n",
       "      <td>2.0252</td>\n",
       "      <td>1.9637</td>\n",
       "      <td>1.9545</td>\n",
       "      <td>1.5714</td>\n",
       "      <td>2.2782</td>\n",
       "      <td>1.7622</td>\n",
       "      <td>2.3628</td>\n",
       "      <td>1.8717</td>\n",
       "      <td>1.8923</td>\n",
       "      <td>1.8589</td>\n",
       "      <td>1.6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laws</th>\n",
       "      <td>2.1410</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.2490</td>\n",
       "      <td>1.5020</td>\n",
       "      <td>1.4633</td>\n",
       "      <td>1.3147</td>\n",
       "      <td>1.4223</td>\n",
       "      <td>1.4369</td>\n",
       "      <td>1.1931</td>\n",
       "      <td>1.4345</td>\n",
       "      <td>1.1875</td>\n",
       "      <td>1.1924</td>\n",
       "      <td>1.6218</td>\n",
       "      <td>1.2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orders1</th>\n",
       "      <td>1.6184</td>\n",
       "      <td>1.0949</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>1.0499</td>\n",
       "      <td>1.1109</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>1.2397</td>\n",
       "      <td>0.8267</td>\n",
       "      <td>1.0124</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orders2</th>\n",
       "      <td>1.8982</td>\n",
       "      <td>1.5244</td>\n",
       "      <td>1.2686</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.3820</td>\n",
       "      <td>1.6840</td>\n",
       "      <td>1.4149</td>\n",
       "      <td>1.6873</td>\n",
       "      <td>1.4492</td>\n",
       "      <td>1.6208</td>\n",
       "      <td>1.4198</td>\n",
       "      <td>1.4526</td>\n",
       "      <td>1.5523</td>\n",
       "      <td>1.3195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simony</th>\n",
       "      <td>1.6667</td>\n",
       "      <td>1.3491</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>1.2195</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>1.1304</td>\n",
       "      <td>1.1287</td>\n",
       "      <td>1.0413</td>\n",
       "      <td>1.1711</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>1.0863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procedure</th>\n",
       "      <td>1.6187</td>\n",
       "      <td>1.1991</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>1.5095</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0790</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>1.0726</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.9852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other1</th>\n",
       "      <td>1.3353</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.0619</td>\n",
       "      <td>1.2722</td>\n",
       "      <td>1.1383</td>\n",
       "      <td>1.0753</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.2792</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>1.3054</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>1.0853</td>\n",
       "      <td>1.3272</td>\n",
       "      <td>0.8152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other2</th>\n",
       "      <td>1.9416</td>\n",
       "      <td>1.3233</td>\n",
       "      <td>1.0913</td>\n",
       "      <td>1.6291</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>1.1090</td>\n",
       "      <td>1.2963</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>1.0346</td>\n",
       "      <td>1.0592</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>1.0961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monastic</th>\n",
       "      <td>1.4555</td>\n",
       "      <td>1.0451</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>1.2676</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>0.7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other3</th>\n",
       "      <td>2.0705</td>\n",
       "      <td>1.3388</td>\n",
       "      <td>1.2890</td>\n",
       "      <td>1.5146</td>\n",
       "      <td>1.1997</td>\n",
       "      <td>1.1057</td>\n",
       "      <td>1.3497</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>1.1229</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.1209</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>1.1521</td>\n",
       "      <td>1.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heresy</th>\n",
       "      <td>1.5177</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>1.1395</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.8484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marriage</th>\n",
       "      <td>1.5448</td>\n",
       "      <td>1.0263</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.2650</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>1.0494</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.8676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penance</th>\n",
       "      <td>1.5371</td>\n",
       "      <td>1.4473</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>1.4005</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>1.3077</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.8101</td>\n",
       "      <td>1.0992</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.8146</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>1.3740</td>\n",
       "      <td>1.0852</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>1.1717</td>\n",
       "      <td>1.0623</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>1.0674</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>1.2408</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cases   laws  orders1  orders2  simony  procedure  other1  other2  \\\n",
       "cases        nan 2.2765   1.9247   2.0252  1.9637     1.9545  1.5714  2.2782   \n",
       "laws      2.1410    nan   1.2490   1.5020  1.4633     1.3147  1.4223  1.4369   \n",
       "orders1   1.6184 1.0949      nan   1.1223  0.9685     0.8843  1.0499  1.1109   \n",
       "orders2   1.8982 1.5244   1.2686      nan  1.3820     1.6840  1.4149  1.6873   \n",
       "simony    1.6667 1.3491   0.9772   1.2195     nan     0.8878  1.1304  1.1287   \n",
       "procedure 1.6187 1.1991   0.8920   1.5095  0.8789        nan  1.0790  1.1223   \n",
       "other1    1.3353 1.3000   1.0619   1.2722  1.1383     1.0753     nan  1.2792   \n",
       "other2    1.9416 1.3233   1.0913   1.6291  1.1386     1.1090  1.2963     nan   \n",
       "monastic  1.4555 1.0451   0.8554   1.2676  1.0114     0.7986  0.9300  0.7429   \n",
       "other3    2.0705 1.3388   1.2890   1.5146  1.1997     1.1057  1.3497  0.9505   \n",
       "heresy    1.5177 1.0310   0.7772   1.2182  0.5544     0.5950  0.9485  0.9839   \n",
       "marriage  1.5448 1.0263   0.9848   1.2650  0.8840     0.9667  1.0494  0.6126   \n",
       "penance   1.5371 1.4473   0.7478   1.4005  0.9024     0.8781  1.3077  0.9152   \n",
       "second    1.3740 1.0852   0.7764   1.1717  1.0623     0.9634  0.7971  1.0674   \n",
       "\n",
       "           monastic  other3  heresy  marriage  penance  second  \n",
       "cases        1.7622  2.3628  1.8717    1.8923   1.8589  1.6334  \n",
       "laws         1.1931  1.4345  1.1875    1.1924   1.6218  1.2323  \n",
       "orders1      0.8693  1.2397  0.8267    1.0124   0.7505  0.7777  \n",
       "orders2      1.4492  1.6208  1.4198    1.4526   1.5523  1.3195  \n",
       "simony       1.0413  1.1711  0.5900    0.9166   0.9059  1.0863  \n",
       "procedure    0.8210  1.0726  0.6569    0.9993   0.8818  0.9852  \n",
       "other1       0.9649  1.3054  0.9960    1.0853   1.3272  0.8152  \n",
       "other2       0.7979  1.0346  1.0592    0.6540   0.8633  1.0961  \n",
       "monastic        nan  1.0578  0.7602    0.6611   0.7999  0.7799  \n",
       "other3       1.1229     nan  1.1209    0.7121   1.1521  1.3067  \n",
       "heresy       0.7672  1.1395     nan    0.7783   0.6756  0.8484  \n",
       "marriage     0.6577  0.6552  0.7672       nan   0.7974  0.8676  \n",
       "penance      0.8101  1.0992  0.7609    0.8146      nan  0.9026  \n",
       "second       0.7861  1.2408  0.8770    0.8796   0.8927     nan  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './corpus/b/'\n",
    "\n",
    "candidates = ['cases', 'laws', 'orders1', 'orders2', 'simony', 'procedure', 'other1', 'other2', 'monastic', 'other3', 'heresy', 'marriage', 'penance', 'second']\n",
    "deltas = pd.DataFrame(columns = candidates)\n",
    "limit = 30 # 30 most frequent words (MFWs)\n",
    "for candidate in candidates:\n",
    "    unknown = candidate\n",
    "    samples = candidates[:]\n",
    "    samples.remove(unknown)\n",
    "    features = get_features(samples)\n",
    "    mfws = list(features.keys())[:limit]\n",
    "    counts = get_counts(mfws, [unknown] + samples)\n",
    "    lengths = get_lengths([unknown] + samples)\n",
    "    frequencies = (counts / lengths.values) * 1000\n",
    "    means = frequencies[samples].mean(axis = 1).to_frame('mean')\n",
    "    standard_deviations = frequencies[samples].std(axis = 1).to_frame('std')\n",
    "    z_scores = (frequencies - means.values) / standard_deviations.values\n",
    "    test = z_scores[[unknown]]\n",
    "    corpus = z_scores[samples]\n",
    "    differences = (test.values - corpus).abs()\n",
    "    row = (differences.mean(axis = 0)).to_frame(unknown).transpose()\n",
    "    deltas = deltas.append(row)\n",
    "# csv = open('./CSVs/deltas.csv', 'w')\n",
    "# csv.write(deltas.to_csv())\n",
    "# csv.close()\n",
    "f.write(deltas[['cases', 'laws', 'orders1', 'orders2', 'simony', 'procedure', 'other1']].round(4).to_markdown() + '\\n\\n')\n",
    "f.write(deltas[['other2', 'monastic', 'other3', 'heresy', 'marriage', 'penance', 'second']].round(4).to_markdown() + '\\n\\n')\n",
    "f.close()\n",
    "deltas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the scale of the experiment, the results can be somewhat difficult to read, but are entirely consistent with those obtained in the previous simplified experiments. They are divided into two tables to allow them to be represented on the printed page, but should be imagined as a single table, with the second table extending the first table to the right. The first column of each row contains the name of the subcorpus hypothesized to be the work of an unknown author. The previously obtained results from the simplified demonstration examples lead us to expect that the cases subcorpus corresponding to the 36 hypothetical case statements or *themata* will have highest value for Burrows's Delta in each row. Remember that the cases subcorpus having the highest Delta value in a given row indicates that it is the *least* likely to have the same author as the subcorpus indicated in the first column and hypothesized to be the work of an unknown author.\n",
    "\n",
    "Disregard the first row---we are not interested in the Delta distance of the cases subcorpus from itself. Read each row starting at the second, comparing the value for the Delta distance between the subcorpus of unknown authorship and the cases subcorpus with the Delta values for each of the other subcorpora. Taking the second row of each table as an example, the value for the Delta distance between the laws and cases subcorpora is 2.141, which is greater than NaN, 1.249, 1.502, 1.4633, 1.3147, 1.4223 in the first table, and continuing on to the corresponding row in the second table, is also greater than 1.4369, 1.1931, 1.4345, 1.1875, 1.1924, 1.6218, and 1.2323. (In each row, the entry corresponding to the Delta distance between the subcorpus of unknown authorship and itself is undefined, and is indicated by \"NaN\", an conventional abbreviation in numerical computing for \"Not a Number\".)\n",
    "\n",
    "For each of the thirteen subcorpora excluding cases, the value for the Burrows's Delta distance between that subcorpus and the cases subcorpus is the highest in the row. In only one row are there Delta values that are even close to the value for the cases subcorpus: for the other1 subcorpus (first-recension *dicta* from *Causae* 7-10), the Delta value for the cases subcorpus is 1.3353, while the Delta values for laws (first-recension *dicta* from the *Tractatus de legibus*), other3 (first-recension *dicta* from *Causae* 21-22), and penance (first- and second-recension *dicta* from *de Penitentia*) are 1.3, 1.3054, and 1.3272 respectively. Even in this case, the Delta value for the cases subcorpus indicates that it is the *least* likely of any of the subcorpora in the row to share an author in common with the other1 subcorpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = pp.subplots()\n",
    "im = ax.imshow(deltas)\n",
    "ax.set_xticks(np.arange(len(candidates)))\n",
    "ax.set_yticks(np.arange(len(candidates)))\n",
    "ax.set_xticklabels(candidates)\n",
    "ax.set_yticklabels(candidates)\n",
    "pp.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "for i in range(len(candidates)):\n",
    "    for j in range(len(candidates)):\n",
    "        # text = ax.text(j, i, deltas.iloc[i,j], ha=\"center\", va=\"center\", color=\"w\")\n",
    "        pass\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
